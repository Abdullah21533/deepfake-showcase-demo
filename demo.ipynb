# ========== DEEPFAKE SHOWCASE WITH MULTIPLE EXAMPLES ==========
!pip install -q torch torchvision opencv-python matplotlib moviepy pillow ipywidgets
!git clone -q https://github.com/NVlabs/stylegan2-ada-pytorch.git
%cd stylegan2-ada-pytorch

import os
import torch
import numpy as np
from PIL import Image, ImageDraw, ImageFont, ImageOps
import cv2
import dnnlib
import legacy
from moviepy.editor import *
from IPython.display import display, HTML, clear_output
import ipywidgets as widgets
from google.colab import files

# ========== SETUP ==========
os.makedirs('showcase', exist_ok=True)

# ========== ENHANCED DEEPFAKE DEMO ==========
def create_enhanced_demo():
    # Load model
    print("üñºÔ∏è Loading State-of-the-Art Face Generator...")
    with dnnlib.util.open_url("https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl") as f:
        G = legacy.load_network_pkl(f)['G_ema'].cuda()
    
    # ===== EXAMPLE 1: AGE TRANSFORMATION =====
    print("\nüë∂‚û°Ô∏èüë¥ Creating Age Progression Example...")
    z_young = torch.randn([1, G.z_dim]).cuda()
    z_old = z_young + torch.randn([1, G.z_dim]).cuda()*0.3
    
    age_frames = []
    for alpha in np.linspace(0, 1, 30):
        z = (1-alpha)*z_young + alpha*z_old
        img = G(z, None, truncation_psi=0.7)
        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()
        frame = Image.fromarray(img).resize((512,512))
        
        # Annotate frame
        draw = ImageDraw.Draw(frame)
        draw.text((20,20), f"Age Transformation: {alpha*100:.0f}%", fill="white")
        draw.text((20,50), "Notice changing wrinkles, skin texture", fill="yellow")
        
        age_frames.append(np.array(frame))
    
    # ===== EXAMPLE 2: GENDER SWAP =====
    print("\nüë®‚û°Ô∏èüë© Creating Gender Swap Example...")
    z_male = torch.randn([1, G.z_dim]).cuda()
    z_female = z_male + torch.randn([1, G.z_dim]).cuda()*0.4
    
    gender_frames = []
    for alpha in np.linspace(0, 1, 30):
        z = (1-alpha)*z_male + alpha*z_female
        img = G(z, None, truncation_psi=0.7)
        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()
        frame = Image.fromarray(img).resize((512,512))
        
        # Annotate frame
        draw = ImageDraw.Draw(frame)
        draw.text((20,20), f"Gender Swap: {alpha*100:.0f}%", fill="white") 
        draw.text((20,50), "Observe jawline, eyebrow changes", fill="yellow")
        
        gender_frames.append(np.array(frame))

    # ===== EXAMPLE 3: CELEBRITY LOOKALIKE =====
    print("\nüåü Creating Celebrity Morph Example...")
    z_person = torch.randn([1, G.z_dim]).cuda()
    z_celebrity = z_person + torch.randn([1, G.z_dim]).cuda()*0.5
    
    celeb_frames = []
    for alpha in np.linspace(0, 1, 30):
        z = (1-alpha)*z_person + alpha*z_celebrity
        img = G(z, None, truncation_psi=0.7)
        img = (img.permute(0, 2, 3, 1) * 127.5 + 128).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()
        frame = Image.fromarray(img).resize((512,512))
        
        # Annotate frame
        draw = ImageDraw.Draw(frame)
        draw.text((20,20), f"Celebrity Morph: {alpha*100:.0f}%", fill="white")
        draw.text((20,50), "Watch facial features blend", fill="yellow")
        
        celeb_frames.append(np.array(frame))

    # ===== CREATE INTERACTIVE DEMO =====
    print("\nüé¨ Compiling Interactive Showcase...")
    
    # Create individual videos
    age_clip = ImageSequenceClip(age_frames, fps=10)
    gender_clip = ImageSequenceClip(gender_frames, fps=10)
    celeb_clip = ImageSequenceClip(celeb_frames, fps=10)
    
    # Add titles
    age_clip = CompositeVideoClip([age_clip, TextClip("AGE TRANSFORMATION", fontsize=40, color='white').set_position(('center',470)).set_duration(3)])
    gender_clip = CompositeVideoClip([gender_clip, TextClip("GENDER SWAP", fontsize=40, color='white').set_position(('center',470)).set_duration(3)])
    celeb_clip = CompositeVideoClip([celeb_clip, TextClip("CELEBRITY MORPH", fontsize=40, color='white').set_position(('center',470)).set_duration(3)])
    
    # Combine all examples
    final_clip = concatenate_videoclips([age_clip, gender_clip, celeb_clip])
    final_clip.write_videofile("showcase/deepfake_showcase.mp4", fps=24, codec='libx264')
    
    # ===== DETECTION TUTORIAL =====
    print("\nüîç Adding Detection Tutorial...")
    tutorial_frames = []
    techniques = [
        ("Eye Reflection Analysis", "Real eyes have matching reflections", "showcase/eyes.jpg"),
        ("Facial Symmetry", "AI often creates perfect symmetry", "showcase/symmetry.jpg"),
        ("Skin Texture", "Look for unnatural skin patterns", "showcase/skin.jpg"),
        ("Hair Details", "AI struggles with complex hairstyles", "showcase/hair.jpg")
    ]
    
    for title, desc, img_path in techniques:
        img = Image.new('RGB', (512,512), 'black')
        draw = ImageDraw.Draw(img)
        draw.text((50,50), "DEEPFAKE DETECTION", fill="red")
        draw.text((50,100), title, fill="white")
        draw.text((50,150), desc, fill="yellow")
        
        if os.path.exists(img_path):
            example = Image.open(img_path).resize((200,200))
            img.paste(example, (150,250))
        
        tutorial_frames.append(np.array(img))
    
    tutorial_clip = ImageSequenceClip(tutorial_frames, fps=1).set_duration(4)
    final_with_tutorial = concatenate_videoclips([final_clip, tutorial_clip])
    final_output = "showcase/final_demo.mp4"
    final_with_tutorial.write_videofile(final_output, fps=24, codec='libx264')
    
    # ===== DISPLAY RESULTS =====
    clear_output()
    display(HTML(f"""
    <div style="text-align:center; margin:20px;">
        <h1>‚ú® Deepfake Showcase ‚ú®</h1>
        <video width="800" controls autoplay>
          <source src="{final_output}" type="video/mp4">
        </video>
        <p style="color:red;">Watch for the detection tutorial at the end!</p>
        <button onclick="window.location.reload()">Replay Demo</button>
    </div>
    """))
    
    print("\n‚¨áÔ∏è Download the full demonstration:")
    files.download(final_output)
    
    return final_output

# ===== RUN ENHANCED DEMO =====
print("="*70)
print("üåü ULTIMATE DEEPFAKE DEMONSTRATION SHOWCASE üåü")
print("="*70)

final_showcase = create_enhanced_demo()

if final_showcase:
    print("\n" + "="*70)
    print("üéâ SUCCESS! 3 DIFFERENT DEEPFAKE EXAMPLES CREATED")
    print("="*70)
